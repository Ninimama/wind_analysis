{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Segoe UI Symbol','simHei','Arial','sans-serif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year:2016\t(105408, 20)\n",
      "year:2017\t(105120, 20)\n",
      "resampled to  (17544, 20)\n"
     ]
    }
   ],
   "source": [
    "# %load_ext line_profiler\n",
    "# %lprun -f \n",
    "years = [2016,2017]\n",
    "resampling_period = '60T'\n",
    "\n",
    "original_data = load_resample_data(years, resampling_period)\n",
    "windfarms_names = original_data.columns.tolist()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data = Capacity Factor (optional) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windfarms = pd.read_excel('NRGstreamData/WindFarms.xlsx').sort_values(by='Asset ID').reset_index(drop = True)\n",
    "# windfarms.head(4)\n",
    "normalized_data = original_data / windfarms['Capacity'].values\n",
    "normalized_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 5\n",
    "kmin = KMeans(n_clusters)\n",
    "X = np.transpose(normalized_data.iloc[:,:])\n",
    "Y = kmin.fit(X)\n",
    "clusters = kmin.labels_\n",
    "clusters\n",
    "\n",
    "clusters = np.array([1, 1, 2, 1, 4, 4, 0, 0, 0, 1, 3, 0, 0, 0, 3, 0, 1, 2, 3, 2])\n",
    "\n",
    "a = {}\n",
    "for c in range(n_clusters):\n",
    "    ind = clusters == c # OR: ind = np.where(clusters==c)[0] --> this generate an np.array of only indices\n",
    "    # a[c] = (normalized_data.iloc[:,ind]).mean(axis=1) : old version\n",
    "    a[c] = (original_data.iloc[:,ind]).sum(axis=1) / (windfarms['Capacity'].iloc[ind].sum())\n",
    "    \n",
    "\n",
    "clustered_data = pd.DataFrame.from_dict(a)\n",
    "clustered_data.columns = ['Cluster {:d}'.format(d) for d in range(1,n_clusters+1)] \n",
    "\n",
    "sum_capacities_each_row = [sum(~(original_data.iloc[i,:].isnull().values) * \n",
    "                                 windfarms['Capacity'].values) for i in range(0,original_data.shape[0])]\n",
    "clustered_data['Total'] = original_data.sum(axis=1)/ sum_capacities_each_row\n",
    "# clustered_data['Total'] = clustered_data.mean(axis=1)\n",
    "# clustered_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide what data to use for further analysis (Original data | Normalized data | clustered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Be catious !\n",
    "data = clustered_data  # Normalized_data  | Original_data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert original numerical data into categorical representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set initial variables\n",
    "alphabet_size=5\n",
    "alphabets = list(string.ascii_uppercase[:alphabet_size]) # ['A', 'B', 'C', 'D', 'E' , ...]\n",
    "alphabets = [ \"○\" , '◔', '◑', '◕', \"●\"] #  \"○\" , '◔', '◑', '◕', \"●\"  OR '▁ ','▃ ', '▄ ', '▆ ', '█ '\n",
    "\n",
    "categorical_reps_df = categorical_rep_mycode_df(data.iloc[:,-20:],data.columns, alphabet_size, alphabets)\n",
    "categorical_reps_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9684"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('◔')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most frequent motifs of a single series (one single windfarm/ one cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenght_time_period = 6\n",
    "\n",
    "# Define to what motifs are we interested ! :)\n",
    "candidate_motifs = [''.join(p) for p in product(alphabets,repeat=lenght_time_period)] # Generate all permutations of alphabets\n",
    "print(\"Number of desired motifs =\", len(candidate_motifs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_here = categorical_reps_df \n",
    "total_plots = 6\n",
    "n_rows = 3 ; figsize_r = 7\n",
    "n_cols = 2 ; figsize_c = 8\n",
    "n_plots = n_rows * n_cols\n",
    "method = 're_findall' #re_findall  OR count\n",
    "Title = 'Most frequent patterns in {} consecutive hours '.format(lenght_time_period)\n",
    "\n",
    "for p in range(int(-(-total_plots//n_plots))):\n",
    "    fig, axar = plt.subplots(n_rows, n_cols,figsize=(figsize_c,figsize_r), dpi=100)\n",
    "    fig.subplots_adjust(hspace=0.25, wspace=0.07*lenght_time_period)        \n",
    "\n",
    "    ind = 0\n",
    "    for i in range(n_plots*p,min(n_plots*(p+1),total_plots)):\n",
    "        r = ind // n_cols\n",
    "        c = ind % n_cols\n",
    "\n",
    "        one_time_series = data_here.iloc[:,i].str.cat(sep='')\n",
    "        motifs_freqs = find_most_freq_motifs2(one_time_series, candidate_motifs, 10, method)\n",
    "        legend = data_here.columns[i]\n",
    "        freqs = [x[1] for x in motifs_freqs]\n",
    "        motifs = [x[0] for x in motifs_freqs]\n",
    "        values= np.array(freqs)/(data.shape[0])\n",
    "        ax = axar[r, c]    \n",
    "        ax.barh(range(len(freqs)), values, color='g', alpha=0.95)\n",
    "        ax.legend([legend],loc='best', fontsize = 9)\n",
    "        ax.set_yticks(range(len(motifs)))\n",
    "        ax.set_yticklabels(motifs) # fontname='Arial'\n",
    "        ax.tick_params(axis='x', labelsize = 8, which='major', pad=0, color = 'b')\n",
    "        ax.tick_params(axis='y', labelsize = 9, which='major', pad=0, color = 'b')\n",
    "\n",
    "        if c == 0:\n",
    "            ax.set_ylabel('Most Frequent Patterns',fontsize=9)\n",
    "        if r == n_rows-1:\n",
    "            ax.set_xlabel('Probabilty',fontsize=11)\n",
    "\n",
    "        # Pad margins so that markers don't get clipped by the axes\n",
    "        ax.margins(0.05)\n",
    "        \n",
    "        ind = ind + 1\n",
    "\n",
    "    fig.savefig(Title+str(p)+'.jpg', papertype='letter', dpi = 300, bbox_inches='tight')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
